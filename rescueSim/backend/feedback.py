import os
import mimetypes
from pydub import AudioSegment
from google.cloud import speech
import openai

# Set up API keys
openai.api_key = os.environ.get("OPENAI_API_KEY")
if not openai.api_key:
    print("OPENAI_API_KEY is not set.")
else:
    print("OPENAI_API_KEY is set.")

# Initialize Google Cloud Speech-to-Text client

def detect_audio_format(file_path):
    """
    Detects the MIME type of the uploaded audio file.

    Args:
        file_path (str): Path to the audio file.

    Returns:
        str: The detected MIME type of the file.
    """
    mime_type, _ = mimetypes.guess_type(file_path)
    return mime_type

def validate_audio_format(file_path):
    """
    Validates if the audio file is in a supported format.

    Args:
        file_path (str): Path to the audio file.

    Raises:
        ValueError: If the file format is unsupported.

    Supported formats:
        - audio/mpeg (.mp3)
        - audio/wav (.wav)
        - audio/flac (.flac)
        - audio/ogg (.ogg)
        - audio/mp4 (.m4a)
    """
    mime_type = detect_audio_format(file_path)
    if mime_type not in ["audio/mpeg", "audio/wav", "audio/flac", "audio/ogg", "audio/mp4"]:
        raise ValueError(f"Unsupported audio format: {mime_type}")

def convert_to_wav(input_path, output_path):
    """
    Converts an audio file to WAV format if it's not already in a compatible format.

    Args:
        input_path (str): Path to the original audio file.
        output_path (str): Path to save the converted WAV file.

    Returns:
        str: Path to the converted WAV file.
    """
    try:
        # Load the input file (including .m4a)
        audio = AudioSegment.from_file(input_path)
        # Convert to mono, 16kHz WAV
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(output_path, format="wav")
        return output_path
    except Exception as e:
        raise RuntimeError(f"Failed to convert file to WAV: {e}")

def transcribe_audio(file_path):
    client = speech.SpeechClient()
    """
    Transcribes the audio file using Google Cloud Speech-to-Text.

    Args:
        file_path (str): Path to the WAV audio file.

    Returns:
        str: The transcription of the audio file.
    """
    try:
        with open(file_path, "rb") as audio_file:
            audio_content = audio_file.read()

        audio = speech.RecognitionAudio(content=audio_content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,  # Matches conversion settings
            language_code="en-US",
        )

        response = client.recognize(config=config, audio=audio)

        # Combine all transcription segments
        transcription = " ".join(result.alternatives[0].transcript for result in response.results)
        return transcription
    except Exception as e:
        raise RuntimeError(f"Error during transcription: {e}")

def format_conversation_log_with_roles(transcription):
    """
    Formats the transcription into alternating Caller and Dispatcher dialogue.

    Args:
        transcription (str): The raw transcription.

    Returns:
        str: Formatted transcription as alternating dialogue.
    """
    try:
        # Provide the transcription to GPT to format as a dialogue
        prompt = (
            "Here is a transcription of a call. "
            "Format it as a dialogue between a Caller and a Dispatcher, alternating lines. "
            f"Transcription:\n{transcription}"
        )

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "system", "content": prompt}],
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        raise RuntimeError(f"Error formatting transcription with GPT: {e}")

def analyze_performance(conversation_log):
    """
    Generates feedback based on the conversation log using GPT.

    Args:
        conversation_log (str): The transcription of the audio.

    Returns:
        str: Feedback generated by GPT.
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a feedback analyzer for 911 dispatch scenarios. "
                        "Analyze the provided conversation log and provide performance feedback."
                        "Be harsh but provide constructive criticism."
                        "Go briefly through the postivies but dig in on the negatives so the dispatcher can learn"
                    ),
                },
                {"role": "user", "content": conversation_log},
            ],
        )
        return response["choices"][0]["message"]["content"]
    except Exception as e:
        raise RuntimeError(f"Error generating feedback: {e}")

def process_audio_feedback(file_path):
    """
    Processes the uploaded audio file to generate a transcription and feedback.

    Args:
        file_path (str): Path to the uploaded audio file.

    Returns:
        tuple: The formatted conversation log and feedback.
    """
    try:
        # Step 1: Validate the audio format
        validate_audio_format(file_path)

        # Step 2: Convert to WAV format if necessary
        wav_path = f"{os.path.splitext(file_path)[0]}.wav"
        if detect_audio_format(file_path) != "audio/wav":
            file_path = convert_to_wav(file_path, wav_path)

        # Step 3: Transcribe the audio
        transcription = transcribe_audio(file_path)

        # Step 4: Format the transcription as a dialogue
        formatted_conversation_log = format_conversation_log_with_roles(transcription)

        # Step 5: Generate feedback
        feedback = analyze_performance(formatted_conversation_log)

        return formatted_conversation_log, feedback
    except Exception as e:
        raise RuntimeError(f"Error processing audio feedback: {e}")
    finally:
        # Cleanup converted files
        if os.path.exists(wav_path):
            os.remove(wav_path)
